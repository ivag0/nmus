{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888393b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# убираем предупреждения\n",
    "warnings.filterwarnings(\"ignore\", message=\".*TorchCodec.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*StreamingMediaDecoder.*\")\n",
    "\n",
    "# класс создания общего датасета\n",
    "class MoodthemeAudioDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_dict, mel_spectr_func):\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        self.labels_dict = labels_dict\n",
    "        self.mel_spectr_func = mel_spectr_func\n",
    "\n",
    "        # множество тегов\n",
    "        self.moodthemes = set()\n",
    "        for tags in labels_dict.values():\n",
    "            self.moodthemes.update(tags)\n",
    "\n",
    "        # сортриуем и преобразуем теги в индексы\n",
    "        self.moodthemes = sorted(list(self.moodthemes))\n",
    "        self.tag_to_idx = {tag: idx for idx, tag in enumerate(self.moodthemes)}\n",
    "        self.num_classes = len(self.moodthemes)\n",
    "\n",
    "        # собираем аудиофайлы и теги\n",
    "        self.audio_files = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for folder_name in os.listdir(data_dir):\n",
    "            folder_path = os.path.join(data_dir, folder_name)\n",
    "            if os.path.isdir(folder_path):\n",
    "                \n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    if self._is_audio_file(file_name):\n",
    "                        key = os.path.join(folder_name, file_name)\n",
    "                        if key in labels_dict:\n",
    "                            full_path = os.path.join(folder_path, file_name)\n",
    "                            self.audio_files.append(full_path)\n",
    "                            \n",
    "                            file_tags = labels_dict[key]\n",
    "                            multi_hot = self._tags_to_multi_hot(file_tags)\n",
    "                            self.labels.append(multi_hot)\n",
    "\n",
    "    # проверка является ли файл аудиофайлом\n",
    "    def _is_audio_file(self, filename):\n",
    "        return filename.lower().endswith(('.wav', '.mp3', '.flac', '.m4a', '.ogg'))\n",
    "    \n",
    "\n",
    "    # преобразует список тегов в multi-hot вектор\n",
    "    def _tags_to_multi_hot(self, tags):\n",
    "        multi_hot = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        for tag in tags:\n",
    "            if tag in self.tag_to_idx:\n",
    "                multi_hot[self.tag_to_idx[tag]] = 1.0\n",
    "        return multi_hot\n",
    "\n",
    "\n",
    "    def get_class_names(self):\n",
    "        return self.moodthemes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_files[idx]\n",
    "        multi_hot_label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            # Получаем mel-спектрограмму\n",
    "            mel_spectrogram = self.mel_spectr_func(audio_path)\n",
    "            \n",
    "            # Добавляем dimension для канала если нужно\n",
    "            if len(mel_spectrogram.shape) == 2:\n",
    "                mel_spectrogram = mel_spectrogram.unsqueeze(0)  # [1, n_mels, time]\n",
    "            \n",
    "            # Преобразуем метку в тензор\n",
    "            label_tensor = torch.tensor(multi_hot_label, dtype=torch.float32)\n",
    "            \n",
    "            return mel_spectrogram, label_tensor\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_path}: {e}\")\n",
    "            # Возвращаем нулевые тензоры в случае ошибки\n",
    "            mel_shape = (1, 128, 1000)  # пример формы\n",
    "            return torch.zeros(mel_shape), torch.zeros(self.num_classes)\n",
    "        \n",
    "\n",
    "def preprocess_audio(audio_path, target_sr = 22050) -> torch.Tensor:\n",
    "    waveform, sr = torchaudio.load(audio_path, normalize=True, channels_first=True)\n",
    "    #уменьшил частоту дискретизации, чтобы ещё меньше датасет весил, а то везде 44100 Гц или почти везде\n",
    "    if sr != target_sr:\n",
    "        waveform = torchaudio.functional.resample(waveform, sr, target_sr)\n",
    "    \n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=target_sr,\n",
    "        n_mels=128,        \n",
    "        n_fft=1024,       \n",
    "        hop_length=256,\n",
    "        f_min=20,\n",
    "        f_max=11025\n",
    "    )(waveform)\n",
    "\n",
    "    mel_spectrogram = torch.log(mel_spectrogram + 1e-6)\n",
    "\n",
    "    return mel_spectrogram[0,:,:512]\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "tags_dict = {}\n",
    "moodthemes = []\n",
    "\n",
    "# открываем подготовленный словрь\n",
    "with open(\"../data/track_tags.pkl\", 'rb') as file:\n",
    "    tags_dict = pickle.load(file)\n",
    "\n",
    "# список тегов\n",
    "for tags in tags_dict.values():\n",
    "    for tag in tags:\n",
    "        if tag not in moodthemes:\n",
    "            moodthemes.append(tag)\n",
    "\n",
    "# создаём датасет\n",
    "dataset = MoodthemeAudioDataset(\n",
    "    data_dir = \"../data/train\",\n",
    "    labels_dict = tags_dict,\n",
    "    mel_spectr_func = preprocess_audio\n",
    ")\n",
    "\n",
    "# разбиваем датасет на train и test\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices, \n",
    "    test_size = 0.02,\n",
    "    train_size = 0.10,       \n",
    "    random_state = 42        # для воспроизводимости\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False)\n",
    "\n",
    "# тут будут классы моделей\n",
    "class SimpleFCModel(nn.Module):\n",
    "    def __init__(self, num_classes: int, input_height: int, input_width: int, hidden_size: int):\n",
    "        super(SimpleFCModel, self).__init__()\n",
    "        \n",
    "        self.input_height = input_height\n",
    "        self.input_width = input_width\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Вычисляем размер после вытягивания в вектор\n",
    "        self.flatten_size = input_height * input_width\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            # Вытягиваем в плоский вектор\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            # Первый скрытый слой\n",
    "            nn.Linear(self.flatten_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),  # для регуляризации\n",
    "            \n",
    "            # Второй скрытый слой (можно добавить больше)\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # Выходной слой\n",
    "            nn.Linear(hidden_size // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca08ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    Простая функция обучения для мультитеговой классификации аудио\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    \n",
    "    for data, targets in pbar:\n",
    "        \n",
    "        data = data.to(device)                          # \n",
    "        targets = targets.to(device)                    # Перемещаем данные на устройство\n",
    "        \n",
    "        optimizer.zero_grad()                           # Обнуляем градиенты\n",
    "        \n",
    "        outputs = model(data)                           # Прямой проход\n",
    "        \n",
    "        loss = criterion(outputs, targets)              # Вычисляем loss\n",
    "        \n",
    "        loss.backward()                                 # \n",
    "        optimizer.step()                                # Обратный проход\n",
    "        \n",
    "        with torch.no_grad():                           # \n",
    "            probs = torch.sigmoid(outputs)              #\n",
    "            predictions = (probs > 0.5).float()         # Сохраняем предсказания и цели для метрик\n",
    "                                                        #\n",
    "            all_targets.append(targets.cpu())           #\n",
    "            all_predictions.append(predictions.cpu())   #\n",
    "        \n",
    "        running_loss += loss.item()                     # Обновляем статистику\n",
    "        \n",
    "        # Обновляем прогресс-бар\n",
    "        current_loss = running_loss / len(loader)       \n",
    "        pbar.set_postfix({'Loss': f'{current_loss:.4f}'})\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    all_predictions = torch.cat(all_predictions)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = (all_predictions == all_targets).float().mean().item()\n",
    "    \n",
    "    # F1-score (macro)\n",
    "    f1 = f1_score(all_targets.numpy(), all_predictions.numpy(), average='macro', zero_division=0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    \n",
    "    return {\n",
    "        'loss': epoch_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Функция оценки для мультитеговой классификации аудио\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Evaluation')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, targets in pbar:\n",
    "            data = data.to(device)                      #\n",
    "            targets = targets.to(device)                # Перемещаем данные на устройство\n",
    "            \n",
    "            outputs = model(data)                       # Прямой проход\n",
    "            \n",
    "            loss = criterion(outputs, targets)          # Вычисляем loss\n",
    "            \n",
    "            probs = torch.sigmoid(outputs)              # \n",
    "            predictions = (probs > 0.5).float()         # Получаем вероятности и предсказания\n",
    "\n",
    "            all_targets.append(targets.cpu())           # \n",
    "            all_predictions.append(predictions.cpu())   #\n",
    "            all_probs.append(probs.cpu())               # Сохраняем для метрик\n",
    "            \n",
    "            running_loss += loss.item()                 # Обновляем статистику\n",
    "            \n",
    "            # Обновляем прогресс-бар\n",
    "            current_loss = running_loss / len(loader)\n",
    "            pbar.set_postfix({'Loss': f'{current_loss:.4f}'})\n",
    "    \n",
    "    # Объединяем все батчи\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    all_predictions = torch.cat(all_predictions)\n",
    "    all_probs = torch.cat(all_probs)\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    accuracy = (all_predictions == all_targets).float().mean().item()\n",
    "    f1 = f1_score(all_targets.numpy(), all_predictions.numpy(), average='macro', zero_division=0)\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    \n",
    "    return {\n",
    "        'loss': epoch_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets,\n",
    "        'probabilities': all_probs\n",
    "    }\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs, save_dir='../data/models'):\n",
    "    # Создаем директорию для сохранения\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Инициализируем лучшие метрики\n",
    "    best_f1 = 0.0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    # История обучения\n",
    "    history = {\n",
    "        'train_loss': [], 'train_accuracy': [], 'train_f1': [],\n",
    "        'val_loss': [], 'val_accuracy': [], 'val_f1': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # Обучение\n",
    "        train_metrics = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Валидация\n",
    "        val_metrics = evaluate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Сохраняем историю\n",
    "        history['train_loss'].append(train_metrics['loss'])\n",
    "        history['train_accuracy'].append(train_metrics['accuracy'])\n",
    "        history['train_f1'].append(train_metrics['f1'])\n",
    "        history['val_loss'].append(val_metrics['loss'])\n",
    "        history['val_accuracy'].append(val_metrics['accuracy'])\n",
    "        history['val_f1'].append(val_metrics['f1'])\n",
    "        \n",
    "        # Выводим метрики\n",
    "        print(f'Train - Loss: {train_metrics[\"loss\"]:.4f}, Acc: {train_metrics[\"accuracy\"]:.4f}, F1: {train_metrics[\"f1\"]:.4f}')\n",
    "        print(f'Val   - Loss: {val_metrics[\"loss\"]:.4f}, Acc: {val_metrics[\"accuracy\"]:.4f}, F1: {val_metrics[\"f1\"]:.4f}')\n",
    "        \n",
    "        # Сохраняем лучшую модель\n",
    "        if val_metrics['f1'] > best_f1:\n",
    "            best_f1 = val_metrics['f1']\n",
    "            best_epoch = epoch\n",
    "            \n",
    "            # Сохраняем модель\n",
    "            best_model_path = os.path.join(save_dir, 'FCmodel_best.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_f1': best_f1,\n",
    "                'val_loss': val_metrics['loss'],\n",
    "                'val_accuracy': val_metrics['accuracy']\n",
    "            }, best_model_path)\n",
    "            print(f'✓ New best model saved! F1: {best_f1:.4f}')\n",
    "        \n",
    "        # Сохраняем бэкап каждые 5 эпох\n",
    "        if epoch % 5 == 0:\n",
    "            backup_path = os.path.join(save_dir, f'FCmodel_{epoch}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_metrics': train_metrics,\n",
    "                'val_metrics': val_metrics,\n",
    "                'history': history,\n",
    "                'best_f1': best_f1,  \n",
    "                'current_val_f1': val_metrics['f1'],\n",
    "            }, backup_path)\n",
    "            print(f'✓ Backup saved: {backup_path}')\n",
    "    \n",
    "    print(f'\\nTraining completed!')\n",
    "    print(f'Best model: epoch {best_epoch}, F1: {best_f1:.4f}')\n",
    "    \n",
    "    return history, best_f1\n",
    "\n",
    "# Функция для загрузки модели\n",
    "def load_model(model, checkpoint_path, optimizer=None):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    print(f'Model loaded from {checkpoint_path}')\n",
    "    print(f'Epoch: {checkpoint[\"epoch\"]}, Val F1: {checkpoint.get(\"val_f1\", \"N/A\")}')\n",
    "    \n",
    "    return checkpoint\n",
    "\n",
    "def plot_history(history, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Строит графики истории обучения для формата из train_model\n",
    "    \n",
    "    Args:\n",
    "        history: словарь из train_model с ключами:\n",
    "            'train_loss', 'train_accuracy', 'train_f1'\n",
    "            'val_loss', 'val_accuracy', 'val_f1'\n",
    "        figsize: размер фигуры\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Создаем subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    fig.suptitle('Training History', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. График Loss\n",
    "    axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_title('Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. График Accuracy\n",
    "    axes[0, 1].plot(epochs, history['train_accuracy'], 'b-', label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 1].plot(epochs, history['val_accuracy'], 'r-', label='Val Accuracy', linewidth=2)\n",
    "    axes[0, 1].set_title('Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # 3. График F1-score\n",
    "    axes[1, 0].plot(epochs, history['train_f1'], 'b-', label='Train F1', linewidth=2)\n",
    "    axes[1, 0].plot(epochs, history['val_f1'], 'r-', label='Val F1', linewidth=2)\n",
    "    axes[1, 0].set_title('F1-Score (Macro)')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('F1-Score')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "    \n",
    "    # 4. Сводный график всех метрик (валидация) - ИСПРАВЛЕННАЯ ЧАСТЬ\n",
    "    axes[1, 1].plot(epochs, history['val_accuracy'], 'g-', label='Val Accuracy', linewidth=2)\n",
    "    axes[1, 1].plot(epochs, history['val_f1'], 'orange', label='Val F1', linewidth=2)\n",
    "    \n",
    "    # ИСПРАВЛЕНИЕ: преобразуем в numpy array перед делением\n",
    "    val_loss = np.array(history['val_loss'])\n",
    "    if max(val_loss) > 0:  # Проверяем чтобы не делить на 0\n",
    "        val_loss_norm = val_loss / max(val_loss)\n",
    "    else:\n",
    "        val_loss_norm = val_loss\n",
    "    \n",
    "    axes[1, 1].plot(epochs, val_loss_norm, 'r-', label='Val Loss (norm)', linewidth=2)\n",
    "    axes[1, 1].set_title('Validation Metrics Summary')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Value')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Выводим лучшие значения\n",
    "    best_val_acc = max(history['val_accuracy'])\n",
    "    best_val_f1 = max(history['val_f1'])\n",
    "    best_epoch_acc = history['val_accuracy'].index(best_val_acc) + 1\n",
    "    best_epoch_f1 = history['val_f1'].index(best_val_f1) + 1\n",
    "    \n",
    "    print(\"Training Results Summary:\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.4f} (epoch {best_epoch_acc})\")\n",
    "    print(f\"Best Validation F1-Score: {best_val_f1:.4f} (epoch {best_epoch_f1})\")\n",
    "    print(f\"Final Validation Loss: {history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"Final Train Accuracy: {history['train_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final Train F1: {history['train_f1'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef872b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация модели\n",
    "model = SimpleFCModel(\n",
    "    num_classes=len(dataset.get_class_names()),\n",
    "    input_height=128,\n",
    "    input_width=512,\n",
    "    hidden_size=256\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Запуск обучения\n",
    "history, best_f1 = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    num_epochs=5,\n",
    "    save_dir='../data/models'\n",
    ")\n",
    "\n",
    "# вывод графиков\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8856545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ../data/models/FCmodel_best.pth\n",
      "Epoch: 1, Val F1: 0.022597383639533532\n",
      "\n",
      " Prediction for: 7400.mp3\n",
      "  -- dark: 0.505\n",
      "  -- film: 0.611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.16224001, 0.18871887, 0.1908976 , 0.11464704, 0.0152881 ,\n",
       "        0.12977386, 0.11931247, 0.20430069, 0.49834076, 0.00795187,\n",
       "        0.04476983, 0.1851877 , 0.50474167, 0.07586961, 0.09089307,\n",
       "        0.05371616, 0.1069052 , 0.1244147 , 0.08459464, 0.13955484,\n",
       "        0.06145494, 0.02307401, 0.61050445, 0.12722939, 0.08689252,\n",
       "        0.0457852 , 0.35765156, 0.37032825, 0.17118411, 0.0810883 ,\n",
       "        0.1789267 , 0.3510151 , 0.27122477, 0.01916159, 0.21072173,\n",
       "        0.42612377, 0.31619397, 0.21093695, 0.04952242, 0.09588888,\n",
       "        0.08292124, 0.24146736, 0.14612049, 0.13461299, 0.16951759,\n",
       "        0.1774612 , 0.10752928, 0.3087906 , 0.03573575, 0.29870623,\n",
       "        0.08306908, 0.1216257 , 0.33548093, 0.0572835 , 0.02912924,\n",
       "        0.24575889, 0.17778079, 0.4892593 , 0.16161305], dtype=float32),\n",
       " ['dark', 'film'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quick_predict(model, audio_path, preprocess_function, class_names, device='cuda', treshold = 0.5):\n",
    "    \"\"\"Упрощенная версия для быстрой проверки\"\"\"\n",
    "    # Убедимся, что модель на правильном устройстве\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    try:\n",
    "        # Препроцессинг\n",
    "        mel_spec = preprocess_function(audio_path)\n",
    "        \n",
    "        # Добавляем batch dimension и перемещаем на устройство\n",
    "        if len(mel_spec.shape) == 3:  # [channels, height, width]\n",
    "            input_tensor = mel_spec.unsqueeze(0)  # [1, channels, height, width]\n",
    "        else:\n",
    "            input_tensor = mel_spec.unsqueeze(0).unsqueeze(0)  # [1, 1, height, width]\n",
    "        \n",
    "        input_tensor = input_tensor.to(device)\n",
    "        \n",
    "        # Предсказание\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "        \n",
    "        # Результаты\n",
    "        print(f\"\\n Prediction for: {os.path.basename(audio_path)}\")\n",
    "        \n",
    "        active_tags = []\n",
    "        for i, (class_name, prob) in enumerate(zip(class_names, probs)):\n",
    "            if prob > treshold:\n",
    "                print(f\"  -- {class_name}: {prob:.3f}\")\n",
    "                active_tags.append(class_name)\n",
    "        \n",
    "        if not active_tags:\n",
    "            print(f\"  ❌ No tags predicted above 0.5 threshold\")\n",
    "            \n",
    "        return probs, active_tags\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during prediction: {e}\")\n",
    "        return None, None\n",
    "\n",
    "best_model = SimpleFCModel(\n",
    "    input_height=128,        \n",
    "    input_width=512,          \n",
    "    hidden_size=256,  \n",
    "    num_classes=len(dataset.get_class_names()),             \n",
    ")\n",
    "\n",
    "load_model(best_model, '../data/models/FCmodel_best.pth')\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "\n",
    "test_audio_path = \"../data/train/00/7400.mp3\"\n",
    "\n",
    "quick_predict(\n",
    "    model=model,\n",
    "    audio_path=test_audio_path,\n",
    "    preprocess_function=preprocess_audio,\n",
    "    class_names=dataset.get_class_names(),\n",
    "    device=device,\n",
    "    treshold = 0.5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
